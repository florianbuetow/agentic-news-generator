{
  "models": [
    {
      "arch": "gemma2",
      "params_billions": 27.0,
      "publisher": "DevQuasar",
      "model_name": "insait-institute.bggpt-gemma-2-27b-it-v1.0/INSAIT-Institute.BgGPT-Gemma-2-27B-IT-v1.0.Q4_K_M.gguf",
      "quantization": "Q4_K_M",
      "size_gb": 16.65
    },
    {
      "arch": "llama",
      "params_billions": 8.0,
      "publisher": "INSAIT-Institute",
      "model_name": "bggpt-7b-instruct-v0.1/BgGPT-7B-Instruct-v0.1.Q4_K_S.gguf",
      "quantization": "Q4_K_S",
      "size_gb": 4.17
    },
    {
      "arch": "qwen3",
      "params_billions": 8.0,
      "publisher": "mlx-community",
      "model_name": "qwen3-embedding-8b-dwq",
      "quantization": "4bit",
      "size_gb": 4.27
    },
    {
      "arch": "qwen3",
      "params_billions": 4.0,
      "publisher": "mlx-community",
      "model_name": "qwen3-embedding-4b-dwq",
      "quantization": "4bit",
      "size_gb": 2.28
    },
    {
      "arch": "gemma3_text",
      "params_billions": 0.3,
      "publisher": "mlx-community",
      "model_name": "embeddinggemma-300m@8bit",
      "quantization": "8bit",
      "size_gb": 0.36624
    },
    {
      "arch": "gemma3_text",
      "params_billions": 0.3,
      "publisher": "mlx-community",
      "model_name": "embeddinggemma-300m@4bit",
      "quantization": "4bit",
      "size_gb": 0.21249
    },
    {
      "arch": "qwen3",
      "params_billions": 0.6,
      "publisher": "mlx-community",
      "model_name": "qwen3-embedding-0.6b-dwq",
      "quantization": "4bit",
      "size_gb": 0.35123
    },
    {
      "arch": "qwen3_moe",
      "params_billions": 30.0,
      "publisher": "qwen",
      "model_name": "qwen/qwen3-30b-a3b-2507",
      "quantization": "4bit",
      "size_gb": 17.19
    },
    {
      "arch": "hidream",
      "params_billions": null,
      "publisher": "city96",
      "model_name": "hidream-i1-full/hidream-i1-full-Q4_K_S.gguf",
      "quantization": "Q4_K_S",
      "size_gb": 10.89
    },
    {
      "arch": "mistral3",
      "params_billions": 24.0,
      "publisher": "lmstudio-community",
      "model_name": "mistral-small-3.2-24b-instruct-2506-mlx@8bit",
      "quantization": "8bit",
      "size_gb": 25.93
    },
    {
      "arch": "mistral3",
      "params_billions": 24.0,
      "publisher": "lmstudio-community",
      "model_name": "mistral-small-3.2-24b-instruct-2506-mlx@6bit",
      "quantization": "6bit",
      "size_gb": 20.03
    },
    {
      "arch": "mistral3",
      "params_billions": 24.0,
      "publisher": "lmstudio-community",
      "model_name": "mistral-small-3.2-24b-instruct-2506-mlx@4bit",
      "quantization": "4bit",
      "size_gb": 13.54
    },
    {
      "arch": "qwen3",
      "params_billions": 8.0,
      "publisher": "deepseek",
      "model_name": "deepseek/deepseek-r1-0528-qwen3-8b",
      "quantization": "4bit",
      "size_gb": 4.62
    },
    {
      "arch": "llama",
      "params_billions": 33.0,
      "publisher": "GGorman",
      "model_name": "wizardcoder-33b-v1.1-mlx",
      "quantization": "8bit",
      "size_gb": 35.43
    },
    {
      "arch": "glm4",
      "params_billions": 32.0,
      "publisher": "mlx-community",
      "model_name": "glm-4-32b-0414",
      "quantization": "8bit",
      "size_gb": 36.66
    },
    {
      "arch": "mistral3",
      "params_billions": 24.0,
      "publisher": "mistralai",
      "model_name": "mistralai/devstral-small-2-2512",
      "quantization": "4bit",
      "size_gb": 14.12
    },
    {
      "arch": "qwen3_moe",
      "params_billions": 30.0,
      "publisher": "qwen",
      "model_name": "qwen/qwen3-coder-30b",
      "quantization": "4bit",
      "size_gb": 17.19
    },
    {
      "arch": "qwen3",
      "params_billions": 4.0,
      "publisher": "qwen",
      "model_name": "qwen/qwen3-4b-thinking-2507",
      "quantization": "4bit",
      "size_gb": 2.28
    },
    {
      "arch": "lfm2",
      "params_billions": 1.2,
      "publisher": "liquid",
      "model_name": "liquid/lfm2-1.2b",
      "quantization": "8bit",
      "size_gb": 1.25
    },
    {
      "arch": "glm4v",
      "params_billions": 9.0,
      "publisher": "zai-org",
      "model_name": "zai-org/glm-4.6v-flash",
      "quantization": "4bit",
      "size_gb": 7.09
    },
    {
      "arch": "gemma3",
      "params_billions": 27.0,
      "publisher": "google",
      "model_name": "google/gemma-3-27b",
      "quantization": "4bit",
      "size_gb": 16.87
    },
    {
      "arch": "nemotron_h",
      "params_billions": 30.0,
      "publisher": "nvidia",
      "model_name": "nvidia/nemotron-3-nano",
      "quantization": "4bit",
      "size_gb": 17.79
    },
    {
      "arch": "qwen3_moe",
      "params_billions": 30.0,
      "publisher": "lmstudio-community",
      "model_name": "qwen3-30b-a3b-thinking-2507-mlx@8bit",
      "quantization": "8bit",
      "size_gb": 32.46
    },
    {
      "arch": "qwen2_5_vl",
      "params_billions": 7.0,
      "publisher": "mlx-community",
      "model_name": "olmocr-2-7b-1025",
      "quantization": null,
      "size_gb": 16.60
    },
    {
      "arch": "qwen3_moe",
      "params_billions": 30.0,
      "publisher": "lmstudio-community",
      "model_name": "qwen3-30b-a3b-thinking-2507-mlx@4bit",
      "quantization": "4bit",
      "size_gb": 17.19
    },
    {
      "arch": "qwen3_moe",
      "params_billions": 30.0,
      "publisher": "lmstudio-community",
      "model_name": "qwen3-30b-a3b-thinking-2507-mlx@6bit",
      "quantization": "6bit",
      "size_gb": 24.82
    },
    {
      "arch": "qwen2",
      "params_billions": 7.0,
      "publisher": "lmstudio-community",
      "model_name": "qwen2.5-7b-instruct-mlx",
      "quantization": "8bit",
      "size_gb": 8.11
    }
  ],
  "metadata": {
    "total_models": 27,
    "description": "Model specifications for benchmark evaluation",
    "date_created": "2026-01-15",
    "notes": [
      "params_billions: Model parameter count in billions (B)",
      "size_gb: Model size on disk in gigabytes (GB)",
      "quantization: Quantization method (4bit, 6bit, 8bit, Q4_K_M, Q4_K_S, Q2, etc.)",
      "null values indicate missing information from source data"
    ]
  }
}
