# Agentic News Generator

An AI-powered YouTube news aggregator that crawls AI-focused YouTube channels, transcribes video content, segments transcripts by topic, and generates a weekly newspaper-style HTML digest using autonomous AI agents.

## Overview

This system automatically:
1. Downloads videos from pre-configured YouTube channels
2. Extracts audio from videos to WAV format
3. Transcribes audio using MLX Whisper (large-v3 model) with multiple output formats
4. Segments transcripts into topic-based sections using AI analysis
5. Aggregates related topic segments across multiple videos
6. Generates news articles from aggregated content using AI agents
7. Produces a newspaper-style HTML digest
8. Archives processed videos to save disk space

## Repository Structure

```
agentic-news-generator/
â”œâ”€â”€ pyproject.toml          # Project dependencies and metadata
â”œâ”€â”€ justfile                # Build and run commands
â”œâ”€â”€ AGENTS.md               # AI agent development rules
â”œâ”€â”€ CLAUDE.md               # Redirect to AGENTS.md
â”œâ”€â”€ README.md               # This file
â”œâ”€â”€ config/                 # Configuration files
â”‚   â”œâ”€â”€ config.yaml        # YouTube channel configuration
â”‚   â”œâ”€â”€ config.yaml.template  # Template for config.yaml
â”‚   â””â”€â”€ semgrep/           # Semgrep rule configurations
â”œâ”€â”€ src/                    # Source code
â”‚   â”œâ”€â”€ main.py           # Main entry point
â”‚   â””â”€â”€ config.py         # Configuration loading
â”œâ”€â”€ scripts/                # Utility scripts
â”‚   â”œâ”€â”€ yt-downloader.sh   # YouTube video downloader
â”‚   â”œâ”€â”€ convert_to_audio.sh  # Video to audio converter
â”‚   â”œâ”€â”€ transcribe_audio.sh  # Audio transcription (MLX Whisper)
â”‚   â””â”€â”€ archive-videos.sh  # Archive processed videos
â”œâ”€â”€ tests/                  # Test suite
â”œâ”€â”€ prompts/                # LLM prompt templates
â””â”€â”€ data/                   # Data files
    â”œâ”€â”€ downloads/         # Downloaded and processed content
    â”‚   â”œâ”€â”€ videos/       # Downloaded videos (by channel)
    â”‚   â”œâ”€â”€ audio/        # Extracted WAV files (by channel)
    â”‚   â””â”€â”€ transcripts/  # Transcripts in multiple formats (by channel)
    â”œâ”€â”€ archive/           # Archived content
    â”‚   â””â”€â”€ videos/       # Processed videos moved here
    â”œâ”€â”€ temp/              # Temporary processing files
    â””â”€â”€ output/            # Generated output files
        â”œâ”€â”€ topics/        # Per-topic aggregated JSON files
        â””â”€â”€ newspaper/     # Generated HTML newspaper
```

## Prerequisites

- **macOS with Apple Silicon** (M1, M2, M3, or later) - Required for MLX Whisper
- Python 3.12 or higher
- [uv](https://github.com/astral-sh/uv) package manager installed
- [just](https://github.com/casey/just) command runner installed
- [FFmpeg](https://ffmpeg.org/) for audio extraction (`brew install ffmpeg`)
- Chrome browser (for YouTube cookie authentication with yt-dlp)

## Setup

### 1. Initialize the Project

Initialize the development environment:

```bash
just init
```

This will:
- Create all required directories
- Set up a virtual environment using `uv`
- Install all dependencies from `pyproject.toml`

### 2. Configure YouTube Channels

Copy the configuration template and edit it:

```bash
cp config/config.yaml.template config/config.yaml
```

Edit `config/config.yaml` to add your YouTube channels. Each channel can be configured with:
- `url`: YouTube channel URL
- `name`: Display name
- `category`: Channel category (optional, for structured format)
- `description` or `what_you_get`: Channel description (for structured format)
- `vibe`: Free-form channel description (alternative flexible format)

Channels can use either:
- **Structured format**: `category` + `description` (or `what_you_get`)
- **Flexible format**: `vibe` only

See `config/config.yaml` for examples of the 16 pre-configured AI-focused channels.

### 3. Environment Variables

Create a `.env` file in the project root for local development:

```bash
# API Keys (if using cloud-based LLM services)
# ANTHROPIC_API_KEY=your_key_here

# LM Studio Configuration (for local LLM)
# LM_STUDIO_BASE_URL=http://localhost:1234/v1
```

Required environment variables will depend on your LLM backend configuration.

## Usage

### Run the Main Application

```bash
just run
```

### View Available Commands

```bash
just
```

Or see detailed help:

```bash
just help
```

### Common Commands

#### Video Processing Pipeline
- `just download-videos` - Download videos from configured YouTube channels
- `just extract-audio` - Convert downloaded videos to WAV audio files
- `just transcribe` - Transcribe audio files using MLX Whisper (large-v3)
- `just archive-videos` - Archive processed videos and clean up audio files

#### Development
- `just init` - Initialize development environment
- `just run` - Run the main application
- `just test` - Run unit tests
- `just test-coverage` - Run tests with coverage report
- `just code-format` - Auto-fix code style and formatting
- `just code-style` - Check code style (read-only)
- `just code-typecheck` - Run type checking with mypy
- `just ci` - Run all validation checks
- `just destroy` - Remove virtual environment

### Video Processing Workflow

The complete video processing pipeline:

```bash
# Step 1: Download videos from YouTube channels
just download-videos

# Step 2: Extract audio from videos (converts to 16kHz mono WAV)
just extract-audio

# Step 3: Transcribe audio using MLX Whisper large-v3
# Generates: .txt, .srt, .vtt, .tsv, .json files
just transcribe

# Step 4: Archive processed videos and clean up audio files
# Moves videos to data/archive/videos/
# Deletes audio files from data/downloads/audio/
just archive-videos
```

**Notes:**
- All operations are idempotent (safe to re-run)
- Files are organized by channel name
- Transcription uses the Whisper large-v3 model for best quality
- Models are cached in `~/.cache/huggingface/hub/`
- Archive step frees up disk space by moving videos and deleting intermediate audio

## Development

### Development Guidelines

For development guidelines and rules, see [AGENTS.md](AGENTS.md).

### Testing

After every change to the code, tests must be executed:

```bash
just test
```

Always verify the program runs correctly:

```bash
just run
```

### Code Quality

The project includes comprehensive code quality checks:

- **Linting & Formatting**: `ruff` for code style and formatting
- **Type Checking**: `mypy` and `pyright` for static type analysis
- **Security**: `bandit` for security vulnerability scanning
- **Dependencies**: `deptry` for dependency hygiene
- **Spelling**: `codespell` for spell checking
- **Static Analysis**: `semgrep` for pattern-based security checks

Run all checks:

```bash
just ci
```

## Configuration

The system is configured via `config/config.yaml`. The configuration defines:

- **Channels**: List of YouTube channels to monitor
  - Each channel has a URL, name, and optional metadata
  - Channels can use structured format (`category` + `description`/`what_you_get`) or flexible format (`vibe`)

See `config/config.yaml` for the current channel configuration.

## Project Status

This project is in active development. Current implementation status:

- âœ… Configuration loading (`src/config.py`)
- âœ… Basic project structure
- âœ… Video downloading pipeline (`scripts/yt-downloader.sh`)
- âœ… Audio extraction pipeline (`scripts/convert_to_audio.sh`)
- âœ… Transcription pipeline with MLX Whisper large-v3 (`scripts/transcribe_audio.sh`)
- âœ… Video archiving and cleanup (`scripts/archive-videos.sh`)
- ðŸš§ Topic segmentation
- ðŸš§ Article generation
- ðŸš§ HTML newspaper generation

### Video Processing Features

- **Multiple Transcript Formats**: Generates .txt, .srt, .vtt, .tsv, and .json files
- **Idempotent Operations**: All scripts skip already-processed files
- **Channel-based Organization**: Files organized by YouTube channel
- **Efficient Processing**: Uses all CPU cores for audio conversion
- **Apple Silicon Optimized**: MLX Whisper leverages Metal acceleration

## License

[Add license information here]
